---
title: "Model Fitting 2"
subtitle: "Fitting distance sampling log-Gaussian Cox process models using inlabru"
author: "Joe Watson and Marie Auger-Méthé"
date: "11/01/2021"
output: 
  html_document:
    css: "CSSdefs.css"
    after_body: footer.html
---

<script src="js/hideOutput.js"></script>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

In this final tutorial, we will learn how to jointly model presence-only opportunistic sightings with survey data within the `inlabru` package. We will demonstrate how to fit the models and predict both the spatial whale intensity and population size.

### Load packages

```{r warning=FALSE, message=FALSE, error=FALSE}
library(rgeos)
library(rgdal)
library(sp)
library(maptools)
library(spatstat)
library(spdep)
library(INLA)
library(inlabru)
library(readxl)
library(lubridate)
library(ggmap)
library(raster)
```

### File set up

Use `getwd()` to verify that you are inside the folder titled: 'DFO_SDM_Workshop_2020'. If not, change this by navigating to the correct folder in the bottom right panel (folder view), opening it, and then clicking "Set as Working Directory" under the tab 'More'.

**JOE: Taken from other tutorial, in case we need here**
*Fitting these models can take a while. For the purposes of this workshop, I have made all the pre-fitted model files available for use via the `readRDS` function.*

*In addition, to get access to the model results quickly, we need to download the pre-compiled modelling result files, which can be found [here](https://ubcca-my.sharepoint.com/:u:/g/personal/joewatto_student_ubc_ca/Ea8lRO_ESL5CgfFSWqOT0LUBzskEWVVA_v6N2B2RZhr67w?email=m.auger-methe%40oceans.ubc.ca&e=TvsrM1).*


Now we can load in the precompiled data, models, and functions.
```{r message=F}
load('./Data/Modelling_Data2_New.RData')
fit <- readRDS('./Model_Files/fit.rds')
fit2 <- readRDS('./Model_Files/fit2.rds')
source('utility_functions.R')
```

Finally, let's turn off (as many) warnings associated with coordinate reference systems. 
```{r}
rgdal::set_rgdal_show_exportToProj4_warnings(FALSE)
rgdal::set_thin_PROJ6_warnings(TRUE)
options("rgdal_show_exportToProj4_warnings"="none")
```

## Incorporating the presence-only whale watch sightings into our models

### Accounting for the un-measured whale-watch effort

We have little knowledge on the activities of the whale-watching vessels and no GPS data is available. Thus, unlike the survey data, we do not have reliable effort data.

Throughout this tutorial, we will assume that the efforts from the two whale-watching companies, as captured in the two whale-watching effort surfaces $\lambda_{eff}$, will be a function of the distance from the two ports. Crucially, we will assume that the effort decreases as a function of distance from the port.

Two important pieces of knowledge are available to us:

* number of daily whale-watch trips that operate from each port

* average trip length from each port

These can be found from the websites of the two whale-watch operators. These two pieces of information can help us to sensibly constrain the model, hopefully giving us more realistic predictions and inference. We will compare the effects of including and excluding this additional information.

### Rescale and buffer the objects with distances to ports 

We have two SpatialPixelsDataFrames `Dist_Brier` and `Dist_Quoddy` that contain the distances from the Brier and Quoddy ports, respectively.

```{r 'map-distPortO', message=FALSE, cache=TRUE}
ggplot() + gg(Dist_Brier) + gg(mesh_land)
ggplot() + gg(Dist_Quoddy) + gg(mesh_land)
```

As we did with depth in the previous tutorial, we need to buffer and rescale these covariates.  Unlike with previous covariates, however, we will fix all buffered values on land equal to a large constant. This will help to ensure that negligible effort is recorded from the whale watch vessels on land through $\lambda_{eff}$.

We show how to do it with the distance to Brier.

```{r 'map-distBrierRescaled', message=FALSE, cache=TRUE}
# 1) Define a set of pixels across our modified domain
pixels_Domain <- as(SpatialPoints(makegrid(Domain_restricted, n=100000),proj4string = Domain@proj4string),'SpatialPixels')

# Extract the average value of distance at the newly created pixel locations
pixels_Domain$Dist_Brier <- over(pixels_Domain,Dist_Brier)$Dist_Brier
# There are some missing values due to newly created pixels being on land
# Fill in missing values with a very large value (1000km).
# This will make the effect of these regions negligible on inference as lambda_eff will be small
pixels_Domain$Dist_Brier[is.na(pixels_Domain$Dist_Brier)] <- 1e3

Dist_Brier <- pixels_Domain
ggplot() + gg(Dist_Brier) + gg(mesh_land)

# There is an infinity value at the port. Change to 0
Dist_Brier$Dist_Brier[is.infinite(Dist_Brier$Dist_Brier)] <- 0
max(Dist_Brier$Dist_Brier)

# Let's scale the Dist covariates closer to the (0,1) scale
Dist_Brier$Dist_Brier <- Dist_Brier$Dist_Brier / 980.7996
```

### Exercise {#ExNew}

Now, please rescale and buffer the distance to Quoddy object.

<div class="fold s o">
```{r 'map-distQuoddyRescaled', message=FALSE, cache=TRUE}
pixels_Domain <- as(SpatialPoints(makegrid(Domain_restricted, n=100000),proj4string = Domain@proj4string),'SpatialPixels')

pixels_Domain$Dist_Quoddy <- over(pixels_Domain,Dist_Quoddy)$Dist_Quoddy
pixels_Domain$Dist_Quoddy[is.na(pixels_Domain$Dist_Quoddy)] <- 1e3

Dist_Quoddy <- pixels_Domain
# There is an infinity value at the port. Change to 0
Dist_Quoddy$Dist_Quoddy[is.infinite(Dist_Quoddy$Dist_Quoddy)] <- 0
# Let's scale the Dist covariates closer to the (0,1) scale
Dist_Quoddy$Dist_Quoddy <- Dist_Quoddy$Dist_Quoddy / 980.7996
ggplot() + gg(Dist_Quoddy) + gg(mesh_land)
```
</div>

### Reminder about distance from port functional form (new chapter after removing above)

In the first workshop, we plotted a histogram of the distance from port at the encounter locations separately for each port. We saw a steadily decreasing relationship and decided that a half-normal function may be reasonable. We will pursue a half-normal relationship for this tutorial. In particular, we will assume for port $i$: $$\textrm{log} \lambda_{i,eff} = \textrm{log} \lambda_{i,WW} - \frac{-d^2}{2\sigma^2_{i,WW}} \\  = \alpha_{i,0} + \alpha_{i,1} d^2$$.

The simplest way to incorporate this into our model, is to define squared distance variables for each port and let the model estimate both $\alpha_{i,0}$ and $\alpha_{i,1}$. Doing this allows `inlabru` to estimate these as linear effects without requiring the use of Taylor linearisation.

```{r, cache=T}
Dist_Quoddy_sq <- as(SpatialPoints(makegrid(Domain_restricted, n=100000),proj4string = Domain@proj4string),'SpatialPixels')

Dist_Brier_sq <- Dist_Quoddy_sq
Dist_Quoddy_sq$Dist_Quoddy_sq <- Dist_Quoddy$Dist_Quoddy^2
Dist_Brier_sq$Dist_Brier_sq <- Dist_Brier$Dist_Brier^2
```

With the covariates all created, we can now define our components and formulae. Unlike before, we need to define a single components object that contains **all** the required components for both the whale watch **and** survey sightings. 

### Define and fit the model

For our first model, we will ignore all available information provided about the daily activities of the whale-watch vessels. Instead, we will 'let the data speak for themselves' and inform the most suitable effort surfaces $\lambda_{eff}$. We will use the data to inform both the shapes and relative magnitudes ($\alpha_{i,1}$ and $\alpha_{i,0}$) of $\lambda_{eff}$ from each port. 

Let's define the necessary components.

```{r 'cmp_WW_combined1', cache=TRUE}
cmp_WW_Combined1 <- ~ 
  mySpatial(main = coordinates, model = matern_land) + 
  mySpatial_Brier(main = coordinates, copy='mySpatial', fixed=T) + #copies the GRF to Brier locations
  mySpatial_Quoddy(main = coordinates, copy='mySpatial', fixed=T) + #copies the GRF to Quoddy locations
  Dist_Quoddy_sq(main=Dist_Quoddy_sq, model='linear') + # half normal shape
  Dist_Brier_sq(main=Dist_Brier_sq, model='linear') + # half normal shape
  Diff_WW_Q_B(1) + # contrast Brier vs Quoddy
  Intercept_WW_Q(1) + # Intercept for Quoddy
  Intercept(1) +
  lsig(1) +
  log_Depth(main = log_Depth, model='linear')
```

There are a lot of new additions to the components. First, we see the addition of `mySpatial_Brier` and `mySpatial_Quoddy`. These define copies of the original spatial field `mySpatial`. To tell `inlabru` that we want to copy the original model, we use the argument `copy = mySpatial`. The argument `fixed = T` tells `inlabru` that we do not want to scale the field by an estimated scalar parameter.
Mathematically, we want to add $Z(s)$ to each linear predictor, not $\beta_{i,Z}Z(s)$, with $\beta_{i,Z}$ defined separately for each port $i$.

Next, are the additions of `Dist_Quoddy_sq` and `Dist_Brier_sq`. These define linear covariates on the respective SpatialPixelsDataFrame objects (i.e. they define the half-normal functions) and hence describe the shape and range of the effort surfaces. These were defined as $\alpha_{i,1}$ earlier. 

Next, we include the scalar parameters `Intercept_WW_Q` and `Diff_WW_Q_B`. These will define the intercept for the Quoddy whale watch port and the relative log intensity of the Brier whale watch port compared with Quoddy. These will help to define the relative total efforts from the two ports. These were defined as $\alpha_{Quoddy, 0}$ and $\alpha_{Brier, 0}-\alpha_{Quoddy, 0}$. We will see why we chose to define the contrast later, when we incorporate prior information.

Note that we also include log_Depth, despite not being found to be 'significant' in the previous workshop. It will become clear why later.

Let's define the two formulae.

```{r 'formulae_combined1', cache=TRUE}
formula_WW_B1 = coordinates ~ mySpatial_Brier +
  Dist_Brier_sq + 
  Intercept_WW_Q + # Notice that we include both the intercept AND contrast term
  Diff_WW_Q_B +
  log_Depth

formula_WW_Q1 = coordinates ~ mySpatial_Quoddy +
  Dist_Quoddy_sq + 
  Intercept_WW_Q + # Notice that we only include the intercept term
  log_Depth
```

These two formulae define the following models: $$\textrm{log} \lambda_{i,obs}(s) = \alpha_{i,0} + \alpha_{i,1}d(s)^2 + \beta X(s) + Z(s)$$.

Note that for $i =$ Brier, $\alpha_{i,0}$ is split into two terms: the Quoddy intercept and the difference/contrast term. We include the port-specific spatial field and the port-specific intercept(s). Note that we do not need to update the formula defined in the previous workshop for the survey data.

In case you forgot, here it is:

```{r, cache=T}
formula_2
```

Now, we use the `like`/`bru` approach to combine all three likelihood objects (from the survey and two ports)! We must define the three likelihood objects using the joint set of components defined above.

```{r 'likeWW1', warning=FALSE, cache=TRUE}
# from the survey model earlier
fit2_like = like(data = Sightings_survey,
            samplers = Effort_survey,
            domain = list(
              coordinates = mesh_land,
              distance = INLA::inla.mesh.1d(seq(0.25, 2, length.out = 30))),
            formula = formula_2,
            family = 'cp')

fit_WW_B1 = like(data = Sightings_Brier_nodup,
           domain = list(
             coordinates = mesh_land),
           formula = formula_WW_B1,
           family = 'cp')

fit_WW_Q1 = like(data = Sightings_Quoddy_nodup,
                 domain = list(
                   coordinates = mesh_land),
                 formula = formula_WW_Q1,
                 family = 'cp')
```

Notice the lack of `samplers` used in defining the likelihoods for the whale watch data. This is because we are assuming that the whole domain can be sampled, but with the actual sampling intensity governed by the half-norm function of distance from port. Alternatively, we could specify `samplers = Domain`. This would automatically exclude any values that lie on land. We choose not to do this as we have manually fixed a large value of distance here, achieving the same effect.

We can now fit the model using `bru`.

```{r 'bruWW1', warning=FALSE, cache=TRUE}
# Slow to fit, so we load a pre-compiled file instead
fit_combined1 <- bru(fit2_like, fit_WW_B1, fit_WW_Q1, components = cmp_WW_Combined1, options = list(bru_max_iter=30))
#fit_combined1 <- readRDS('./Model_Files/fit_combined1.rds')
```

To run the models yourself, with the initial values set close to the convergence values, run the following instead:

```{r, eval=F}
fit_combined1 <- bru(fit2_like, fit_WW_B1, fit_WW_Q1, components = cmp_WW_Combined1, 
                     options = bru_options(bru_initial=readRDS('./Model_Files/states_combined1.rds'),
            bru_max_iter = 1))
```


Let's look at the results.

```{r 'bruResultsWW1', warning=FALSE, cache=TRUE}
fit_combined1$dic$dic #DIC is 2259 - new benchmark can't compare with previous models
summary(fit_combined1)
```

The output from `summary` shows some interesting findings! 

We detect a large negative effect of the scaled squared distance from port (`Dist_Quoddy_sq` and `Dist_Brier_sq`). This is expected. Remember: $$Dist\_i\_sq = \frac{-1}{2\sigma_i^2}$$ and $\sigma_i^2$ must be positive and we rescaled the distance values to [0,1], so $\sigma_i^2$ should be small! Ultimately, we detect a decreasing effort intensity as the distance from the port increases.

Most interestingly, we detect a large 'significant' effect of log_Depth on the whale intensity. The 'significance' comes from the 95% credible intervals that lie far from 0. This is in agreement with the (crude) IPP model we fit in the exploratory analysis, but opposes the model we fit to the survey data! Remember - we failed to detect any effect of log_Depth in the previous workshop from the survey data alone! Thus, it appears that we may have gained a substantial amount of power to detect species-environmental trends by incorporating the whale-watch data into our model! Importantly, this could help to improve the spatial predictions of the whale intensity too! 

However, we also detect a **wild** value of the Watanabe-Akaike information criterion (WAIC). WAIC is a competitor to DIC for performing model comparison. A wild WAIC (or DIC) value can often be a sign that the model is having convergence issues (is nearly singular). This instability is consistently seen throughout the remainder of this workshop session. The instability is due to us fitting a very complex model to a very limited sample size (only 63 survey sightings!). In practice, we should not confidently report results from such a model. However, for the purposes of this workshop, we continue and report the DIC results. We purposefuly chose a small subset of the data so that models could be fit quickly and efficiently, without having to wait hours for results!

### Investigating the estimated effort layer

Next, we will investigate the estimated effort surface $\lambda_{eff}$ from each port.

First we plot Brier:

```{r 'map-effotWW1Brier', message=FALSE, cache=TRUE}
# Create a SpatialPixelsDataFrame object across our (original) domain
Dist_Brier_sq_plot <- pixels(mesh=mesh_land,mask=Domain)
# Predict the value of lambda_eff across the pixels
Dist_Brier_sq_plot <- predict(fit_combined1,Dist_Brier_sq_plot,~exp(Dist_Brier_sq + Intercept_WW_Q + Diff_WW_Q_B - Intercept), n.samples = 20, seed=seed)

# Plot the predictions!
ggplot() + gg(Dist_Brier_sq_plot[1]) + gg(Domain) +        colsc(c(Dist_Brier_sq_plot$mean)) +
    ggtitle('Effort surface for Brier')

```

### Exercise ?? {#ExNew2}
Repeat the above for the Quoddy port. Plot the effort intensity from both ports using multiplot. Fix the colour scale for both plots

<div class="fold s o">
```{r 'map-effotWW1Quoddy', message=FALSE, cache=TRUE}
Dist_Quoddy_sq_plot <- pixels(mesh=mesh_land,mask=Domain)
Dist_Quoddy_sq_plot <- predict(fit_combined1,Dist_Quoddy_sq_plot,~exp(Dist_Quoddy_sq + Intercept_WW_Q - Intercept),n.samples = 20, seed=seed)

multiplot(
ggplot() + gg(Dist_Quoddy_sq_plot[1]) + gg(Domain) +        colsc(c(Dist_Brier_sq_plot$mean,Dist_Quoddy_sq_plot$mean)) +
    ggtitle('Effort surface for Quoddy'),
ggplot() + gg(Dist_Brier_sq_plot[1]) + gg(Domain) +        colsc(c(Dist_Brier_sq_plot$mean,Dist_Quoddy_sq_plot$mean)) +
    ggtitle('Effort surface for Brier')
)

```
</div>

We see that the vessels from Brier are estimated to travel further from port compared with those from Quoddy which are estimated to stay very close to port. Next, we ask the question: 'how much total effort is being predicted from each port?' 

To answer this, we look at the estimated relative total effort from the two companies Brier/Quoddy:
```{r 'map-effotWW1Quoddy2', message=FALSE, cache=TRUE}
Rel_Effort <-  
  predict(fit_combined1, predpts, 
          ~ sum(weight * exp(Dist_Brier_sq + Diff_WW_Q_B)) / 
            sum(weight * exp(Dist_Quoddy_sq)), 
          n.samples = 20, seed=seed)
# Note the cancellation of the two Intercept terms that are shared!
Rel_Effort
```

We estimate that in total, the effort from the Brier port is around ~1.5 times greater than that from the Quoddy port. The effort is defined relative to the survey effort. This finding will be called into question later.

Now, we plot the estimated intensity from the joint model **and** from the previous covariate model fit exclusively to the survey data. Then, we estimate the whale population size.

```{r, message=F, cache=TRUE}
plot_pixels_WW1 <- pixels(mesh_land, mask = Domain)

pred_int_WW1 <- predict(
  fit_combined1,
  plot_pixels_WW1,
  ~ exp(mySpatial + Intercept + log_Depth),
  n.samples = 20,
  seed = seed
)

multiplot(
  ggplot() + gg(pred_int2[1]) + gg(Domain) + 
    gg.spatiallines_mod(Effort_survey, colour ='red') +
    colsc(c(pred_int2@data$mean, pred_int_WW1@data$mean)) + 
    ggtitle('Covariate Model Mean'),
  ggplot() + gg(pred_int2[2]) + gg(Domain) + 
    gg.spatiallines_mod(Effort_survey, colour = 'red') +
    colsc(c(pred_int2@data$sd, pred_int_WW1@data$sd)) + 
    ggtitle('Covariate Model SD'),
  ggplot() + gg(pred_int_WW1[1]) + gg(Domain) + 
    gg.spatiallines_mod(Effort_survey, colour ='red') +
    colsc(c(pred_int2@data$mean, pred_int_WW1@data$mean)) + 
    ggtitle('Joint Model Mean'),
  ggplot() + gg(pred_int_WW1[2]) + gg(Domain) + 
    gg.spatiallines_mod(Effort_survey, colour = 'red') +
    colsc(c(pred_int2@data$sd, pred_int_WW1@data$sd)) + 
    ggtitle('Joint Model SD'),
  layout = matrix(
    c(1:4),
    nrow = 2,
    ncol = 2,
    byrow = F
  )
)

# What is the estimated population size?
Lambda_WW1 <- predict(fit_combined1, predpts, 
                      ~ sum(weight * exp(mySpatial + Intercept + log_Depth)),
                      n.samples = 20, seed=seed)
Lambda_WW1
Lambda_df <- rbind(Lambda_WW1,Lambda,Lambda2)
Lambda_df$Model <- c('Joint Model 1','Survey-only no depth','Survey-only with depth')
ggplot(Lambda_df,aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar()

```

Extrapolation error may be severe here. The estimated intensity becomes very large as we head South-East from the tracklines. This is because the model-estimated log_Depth effect has been extrapolated to values of log_Depth beyond those seen near the survey tracklines or ports. Since we do not trust this extrapolation of the log_Depth effect outside the observed range of log_Depth values, it is crucial that we restrict our plot to areas close to the tracklines. We choose 'close' to mean within 30 km of the nearest trackline, and restrict our pixels accordingly.

```{r, warning=F, message=F, cache=TRUE}
#compute the indices of the pixels that lie < 30km of nearest trackline
restricted_ind <-
  which(apply(gWithinDistance(
    as(pred_int2, 'SpatialPoints'),
    Effort_survey,
    dist = 30,
    byid = T
  ), 2, sum) > 0)

# Extract only those pixels
pred_int2_restricted <- pred_int2[restricted_ind,]
pred_int_WW1_restricted <- pred_int_WW1[restricted_ind,]

# Plot the restricted pixels
multiplot(ggplot() + gg(pred_int2_restricted[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int2_restricted@data$mean,pred_int_WW1_restricted@data$mean),probs = c(0.000,1))) + ggtitle('Covariate Model Mean'),
          ggplot() + gg(pred_int2_restricted[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int2_restricted@data$sd,pred_int_WW1_restricted@data$sd),probs = c(0.001,1))) + ggtitle('Covariate Model SD'),
          ggplot() + gg(pred_int_WW1_restricted[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int2_restricted@data$mean,pred_int_WW1_restricted@data$mean),probs = c(0.001,1))) + ggtitle('Joint Model Mean'),
          ggplot() + gg(pred_int_WW1_restricted[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int2_restricted@data$sd,pred_int_WW1_restricted@data$sd),probs = c(0.001,1))) + ggtitle('Joint Model SD'),
          layout = matrix(c(1:4),nrow=2,ncol=2,byrow = F))


# What is the estimated population size in the restricted region?
Lambda_WW1_restricted <- predict(fit_combined1, predpts_restricted, ~ sum(weight * exp(mySpatial + Intercept +
                                                                              log_Depth)), n.samples = 20, seed=seed)
Lambda_WW1_restricted
Lambda_df_restricted <- rbind(Lambda_WW1_restricted,Lambda_restricted,Lambda2_restricted)
Lambda_df_restricted$Model <- c('Joint Model 1','Survey-only no depth','Survey-only with depth')
ggplot(Lambda_df_restricted,aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar() + ggtitle('Estimated Population Size in Restricted Region')
```

We see that the estimated population sizes within the restricted domain are much similar compared with those across the whole domain. However, we still see that the joint model predicts that a larger population of whales is present. Additionally, the posterior distributions of the total population size are more variable under the joint model compared with the survey-only model. 

Qualitiatively, the intensity surfaces from the joint and survey-only models appear similar. 'Hotspots' are mostly consistent across the two models, albeit with some slight evidence of a higher whale intensity being present around the whale watch ports. However, under the joint model, the 'hotspots' of whale activity detected by the survey-only model become much more pronounced. This is likely due to a large log_Depth effect being detected (try plotting log_Depth to see for yourself!). 

### Incorporating external information into the model for the presence-only sightings

For our second model, we will use the available information on the fleet sizes of the two whale watch companies and the number and duration of trips that leave each port. Looking at the two websites, we find the following information:

- There are 3 vessels that depart from Brier vs 1 from Quoddy
- Quoddy has 2 trips per day @ 2.75hours before July 10th and 3 daily trips after
- Brier has 2 daily trips @ 4 hours before July 11th and 3 daily trips after. 
- Brier also has 5 daily trips @ 2.25 hours before July 11th and 6 after
- Thus the estimated total summer boat hours are 651.75 for Quoddy and 2096 for Brier
- We estimate Brier to have 3.22 times more effort on the water than Quoddy

Note that the previous model estimated Brier's effort surface to be only ~1.5 times bigger! This is unrealistic... Instead, in model 2, we will fix the total effort from Brier equal to 3.22 times that of Quoddy. To achieve this, we will replace the contrast term (`Diff_...`) with a log(3.22) offset to the Brier linear predictor. This is the reason we defined the model in terms of a contrast!


Note that we also need to define an integration function to integrate the distance function across the domain, with the current guess of the parameters Dist_Brier_sq and Dist_Quoddy_sq. We will use these to normalise the two effort surfaces $\lambda_{eff}$ and put them on the same scale. Let's define these now. 

```{r, cache=T}
# These approximate the integral of the (unscaled) effort surface and returns the negative logarithm. Needs to return negative log as we need to subtract the integral on the log lambda_eff scale (equivalent to dividing on original scale)
int_dist_Brier <- function(par){
  return(-log(sum(exp(Dist_Brier_sq@data[,1]*par))/2000))
}
int_dist_Quoddy <- function(par){
  return(-log(sum(exp(Dist_Quoddy_sq@data[,1]*par))/2000))
}
```

Note that we divide the total sum by 2000 to rescale the values to a more sensible range to avoid numerical instabilities. Computing the relative values by division will cancel out the '2000'.

With these two normalising functions defined, we can now define the components and formulae. There are many ways of defining the model. The one we show has been chosen for its ease of reading. Unlike before, instead of defining `model='linear'` for the two `Dist_X_sq` variables, we instead define model='offset' and separately define scalar parameters `Quoddy_par` and `Brier_par`. This allows us to more easily define the normalising terms `int_dist_X` in the linear predictors. Note that `model=offset` here simply extracts the desired value of the covariates, without scaling it by a parameter.

More precisely, for $i \in \{\textrm{Quoddy, Brier}\}$, `Dist_i_sq` will no longer be the product term $\alpha_{i,1}d(s)^2$, but instead will simply be $d(s)^2$. `i_par` will now serve the role as $\alpha_{i,1}$. We will manually multiply these together in the formula within `like()`.

```{r, cache=T}
cmp_WW_Combined2 <- 
  ~ mySpatial_Brier(main = coordinates, copy='mySpatial', fixed=T) + 
  mySpatial_Quoddy(main = coordinates, copy='mySpatial', fixed=T) + 
  Dist_Quoddy_sq(main=Dist_Quoddy_sq, model='offset') +
  Dist_Brier_sq(main=Dist_Brier_sq, model='offset') +
  Intercept_WW_Q(1) +
  mySpatial(main = coordinates, model = matern_land) + 
  Intercept(1) +
  lsig(1) +
  Quoddy_par(1) + # Define these as scalar parameters!
  Brier_par(1) +
  log_Depth(main = log_Depth, model='linear')

formula_WW_B2 = coordinates ~ mySpatial_Brier +
  Dist_Brier_sq*Brier_par + # Notice the product!
  Intercept_WW_Q + log(3.22) +
  log_Depth +
  int_dist_Brier(Brier_par) # We add this normalising function

formula_WW_Q2 = coordinates ~ mySpatial_Quoddy +
  Dist_Quoddy_sq*Quoddy_par + # Notice the product!
  Intercept_WW_Q  +
  log_Depth +
  int_dist_Quoddy(Quoddy_par) # We add this normalising function

```
Note that `Diff_WW_Q_B` has been replaced with `log(3.22)` based on the reported trip numbers and durations. Note also, that `Dist_Brier_sq` and `Dist_Quoddy_sq` are multiplied by `Brier_par` and `Quoddy_par` respectively in the formula objects, due to them being offsets.  

Now we can define the likelihoods and fit the models

```{r, cache=TRUE}
fit_WW_B2 = like(data = Sightings_Brier_nodup,
                 domain = list(
                   coordinates = mesh_land),
                 formula = formula_WW_B2,
                 family = 'cp',
                 allow_latent = T)

fit_WW_Q2 = like(data = Sightings_Quoddy_nodup,
                 domain = list(
                   coordinates = mesh_land),
                 formula = formula_WW_Q2,
                 family = 'cp',
                 allow_latent = T)

# Slow
# fit_combined2 <- 
#   bru(fit2_like, fit_WW_B2, fit_WW_Q2, components = cmp_WW_Combined2,
#                      options = list(bru_initial = list(Brier_par = -100,
#                                                        Quoddy_par = -100)))
fit_combined2 <- readRDS('./Model_Files/fit_combined2.rds')
fit_combined2$dic$dic #DIC is 2326.411 - substantially worse fit.
summary(fit_combined2)
```

Again, to run this yourself with the known initial values, run:
```{r, eval=F}
fit_combined2 <- bru(fit2_like, fit_WW_B2, fit_WW_Q2, components = cmp_WW_Combined2,, 
                     options = bru_options(bru_initial=readRDS('./Model_Files/states_combined2.rds'),
            bru_max_iter = 1))
```


From the summary output, we see that the DIC for this model is larger than the previous unconstrained model. Once again, the WAIC is unstable, indicating model convergence issues. Despite the **larger** DIC, we would likely prefer the results from this model over the first model. We saw before that the unconstrained model led to unrealistic predictions of the relative total amounts of effort from the two ports. Let's investigate the predicted intensity and estimated population size.

```{r, message=F, warning=F, cache=TRUE}
# Plot the effort surfaces from the two WW companies/ports
Dist_Brier_sq_plot2 <- pixels(mesh=mesh_land,mask=Domain)
Dist_Brier_sq_plot2 <- predict(fit_combined2,Dist_Brier_sq_plot2,~exp(Intercept_WW_Q + log(3.22) + Dist_Brier_sq*Brier_par),n.samples = 20, seed=seed)
ggplot() + gg(Dist_Brier_sq_plot2[1]) + gg(Domain) + colsc(Dist_Brier_sq_plot2[1]$mean) +
    ggtitle('Effort surface for Brier')
Dist_Quoddy_sq_plot2 <- pixels(mesh=mesh_land,mask=Domain)
Dist_Quoddy_sq_plot2 <- predict(fit_combined2,Dist_Quoddy_sq_plot2,~exp(Intercept_WW_Q + Dist_Quoddy_sq*Quoddy_par),n.samples = 20, seed=seed)
ggplot() + gg(Dist_Quoddy_sq_plot2[1]) + gg(Domain) + colsc(Dist_Quoddy_sq_plot2[1]$mean) +
    ggtitle('Effort surface for Quoddy')

# Plot the (effort-corrected) whale intensity
plot_pixels_WW2 <- pixels(mesh_land, mask = Domain)
pred_int_WW2 <- predict(fit_combined2, plot_pixels_WW2, 
                        ~ exp(mySpatial + Intercept + log_Depth), n.samples = 20, seed=seed)

# threshold the colour palette at the 99.5th percentile for nicer viewing
multiplot(ggplot() + gg(pred_int_WW1[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$mean,pred_int_WW2@data$mean),probs = c(0.005,0.995))) + ggtitle('Joint Model 1 Mean'),
          ggplot() + gg(pred_int_WW1[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$sd,pred_int_WW2@data$sd),probs = c(0.005,0.995))) + ggtitle('Joint Model 1 SD'),
          ggplot() + gg(pred_int_WW2[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$mean,pred_int_WW2@data$mean),probs = c(0.005,0.995))) + ggtitle('Joint Model 2 Mean'),
          ggplot() + gg(pred_int_WW2[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$sd,pred_int_WW2@data$sd),probs = c(0.005,0.995))) + ggtitle('Joint Model 2 SD'),
          layout = matrix(c(1:4),nrow=2,ncol=2,byrow = F))

# We may be extrapolating too far here. Let's restrict our plot to those pixels within 30 km of nearest trackline
pred_int_WW2_restricted <- pred_int_WW2[restricted_ind,]
multiplot(ggplot() + gg(pred_int_WW1_restricted[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$mean,pred_int_WW2_restricted@data$mean)) + ggtitle('Joint Model 1 Mean'),
          ggplot() + gg(pred_int_WW1_restricted[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$sd,pred_int_WW2_restricted@data$sd)) + ggtitle('Joint Model 1 SD'),
          ggplot() + gg(pred_int_WW2_restricted[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$mean,pred_int_WW2_restricted@data$mean)) + ggtitle('Joint Model 2 Mean'),
          ggplot() + gg(pred_int_WW2_restricted[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$sd,pred_int_WW2_restricted@data$sd)) + ggtitle('Joint Model 2 SD'),
          layout = matrix(c(1:4),nrow=2,ncol=2,byrow = F))

# What is the estimated popualation size?
Lambda_WW2 <- predict(fit_combined2, predpts, ~ sum(weight * exp(mySpatial + Intercept +
                                                                   log_Depth)), n.samples = 20, seed=seed)
Lambda_WW2
Lambda_df <- rbind(Lambda_WW1,Lambda_WW2,Lambda,Lambda2)
Lambda_df$Model <- c('Joint Model 1','Joint Model 2','Survey-only no depth','Survey-only with depth')
ggplot(Lambda_df,aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar()
# and in the restricted region?
Lambda_WW2_restricted <- 
  predict(fit_combined2, predpts_restricted, 
          ~ sum(weight * exp(mySpatial + Intercept + log_Depth)), 
          n.samples = 20,seed=seed)
Lambda_WW2_restricted
Lambda_df_restricted <- rbind(Lambda_WW1_restricted,Lambda_WW2_restricted,Lambda_restricted,Lambda2_restricted)
Lambda_df_restricted$Model <- c('Joint Model 1','Joint Model 2','Survey-only no depth','Survey-only with depth')
ggplot(Lambda_df_restricted,aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar() + ggtitle('Estimated Population Size in Restricted Region')

# Sanity Check: is 3.22 is contained in the approximate 95% credible intervals?
# The order of division is reversed due to the negative sign in the function
Rel_Effort2_pixels <- pixels(mesh=mesh_land,mask=Domain)
Rel_Effort2 <-  
  predict(fit_combined2, Rel_Effort2_pixels, 
          ~ exp(int_dist_Quoddy(Quoddy_par))/
            exp(int_dist_Brier(Brier_par)), 
          n.samples = 20, seed=seed)
Rel_Effort2 # Good
```

From the output of model 2 we find a very similar estimate for the effect of log_Depth. We see that the range of the Quoddy vessels is estimated to exceed those from Brier, which is the opposite finding from the previous model (although credible intervals do overlap).

Maps of the fitted intensity show a qualitatively similar appearance, albeit with evidence of numerical instability in the random field in the Southern corners of the domain. This instability is reflected in the very large upper credible intervals for the total population size throughout the domain. Future work should correct for this numerical instability if predictions are desired throughout the entire domain.

To avoid this numerical instability, and to further reduce the risk of extrapolation error, we once again restrict our predictions to the smaller domain. We find large agreement between all 4 models, with the joint models both predicting larger population sizes. Note that the credible intervals for the population size all overlap.

### Including external knowledge about the presence-only observers as a Bayesian prior

We now move on to our third and final model. In the first model, we completely ignored all available information about the relative amounts of effort from each of the two whale watch ports. In the second model, we calculated an estimate for the relative total effort and put a **hard constraint** on the model with this estimate as a fixed offset term.

In reality, neither approach is ideal. We do not know for certain that the total effort from Brier exceeded that of Quoddy by a factor of 3.22. The reported trip times are merely estimates; the reported number of daily departures fail to account for cancellation days due to bad weather or poor turnout. There may exist biases between the two companies with regards to exceeding or failing to meet the advertised trip duration. In summary, there are numerous reasons why our estimate effort ratio of 3.22 may be innacurate. 

To capture this uncertainty, we can use Bayesian machinery and define a prior distribution on the the relative total effort. We put a normal prior on the log scale factor, centered at log(3.22), with a prior standard deviation of 0.1. Thus, a-priori, we put a prior probability of 0.95 that that the ratio of effort between Brier vs Quoddy is between 2.6 and 3.9. 

We now define the shared components and the formulae. Then, we define the likelihood objects and fit the joint model using `bru`.

```{r, cache=TRUE}
cmp_WW_Combined3 <- ~ mySpatial_Brier(main = coordinates, copy='mySpatial', fixed=T) + 
  mySpatial_Quoddy(main = coordinates, copy='mySpatial', fixed=T) + 
  Dist_Quoddy_sq(main=Dist_Quoddy_sq, model='offset') +
  Dist_Brier_sq(main=Dist_Brier_sq, model='offset') +
  Intercept_WW_Q(1) +
  Diff_QQ_B_Q(main=1,model='linear',mean.linear=1.17, prec.linear=100) + # prior!
  mySpatial(main = coordinates, model = matern_land) + 
  Intercept(1) +
  lsig(1) +
  Quoddy_par(1) +
  Brier_par(1) +
  log_Depth(main = log_Depth, model='linear')

formula_WW_B3 = coordinates ~ mySpatial_Brier +
  Dist_Brier_sq*Brier_par + 
  Intercept_WW_Q + 
  Diff_QQ_B_Q +
  log_Depth +
  int_dist_Brier(Brier_par)

formula_WW_Q3 = coordinates ~ mySpatial_Quoddy +
  Dist_Quoddy_sq*Quoddy_par + 
  Intercept_WW_Q +
  log_Depth +
  int_dist_Quoddy(Quoddy_par)

fit_WW_B3 = like(data = Sightings_Brier_nodup,
                 domain = list(
                   coordinates = mesh_land),
                 formula = formula_WW_B3,
                 family = 'cp')

fit_WW_Q3 = like(data = Sightings_Quoddy_nodup,
                 domain = list(
                   coordinates = mesh_land),
                 formula = formula_WW_Q3,
                 family = 'cp')

# fit_combined3 <- bru(fit2_like, fit_WW_B3, fit_WW_Q3, components = cmp_WW_Combined3)
fit_combined3 <- readRDS('./Model_Files/fit_combined3.rds')
fit_combined3$dic$dic #DIC is 2308 - performance in-between the other 2 models
summary(fit_combined3)
```

Again, to run this yourself with the known initial values, run:
```{r, eval=F}
fit_combined3 <- bru(fit2_like, fit_WW_B3, fit_WW_Q3, components = cmp_WW_Combined3, 
                     options = bru_options(bru_initial=readRDS('./Model_Files/states_combined3.rds'),
            bru_max_iter = 1))
```


The components are almost identical to the second model, with the exception of the re-inclusion of the `Diff_QQ_B_Q` term in both the components and the formulae. Unlike with model 1 however, we define the prior distribution by including the lines `,model='linear',mean.linear=1.17, prec.linear=100`. By default, a Gaussian prior is placed on this parameter and we specified both the prior precision (the inverse of the variance) with `prec.linear` and the prior mean with `mean.linear`. Note that 1.17 = log(3.22). 

We find that the DIC of this model lies in-between the first (unconstrained) and second (hard-constrained) models' DIC values, as expected. The estimated effect of log_Depth is very similar to the previous two models. 

Next, we plot the estimated intensity surface and estimated population size.

```{r, message=F, cache=TRUE}
Dist_Brier_sq_plot3 <- pixels(mesh=mesh_land,mask=Domain)
Dist_Brier_sq_plot3 <- predict(fit_combined3,Dist_Brier_sq_plot3,~exp(Dist_Brier_sq*Brier_par + Intercept_WW_Q + Diff_QQ_B_Q),n.samples = 20, seed=seed)
ggplot() + gg(Dist_Brier_sq_plot3[1]) + colsc(Dist_Brier_sq_plot3[1]$mean) + 
  gg(Sightings_Brier_nodup,colour='green') + gg(Domain) +
  ggtitle('Brier Effort')
Dist_Quoddy_sq_plot3 <- pixels(mesh=mesh_land,mask=Domain)
Dist_Quoddy_sq_plot3 <- predict(fit_combined3,Dist_Quoddy_sq_plot3,~exp(Dist_Quoddy_sq*Quoddy_par + Intercept_WW_Q),n.samples = 20, seed=seed)
ggplot() + gg(Dist_Quoddy_sq_plot3[1]) + colsc(Dist_Quoddy_sq_plot3[1]$mean) + 
  gg(Sightings_Quoddy_nodup,colour='green') + gg(Domain) +
  ggtitle('Quoddy Effort')

plot_pixels_WW3 <- pixels(mesh_land, mask = Domain)

pred_int_WW3 <- predict(fit_combined3, plot_pixels_WW3, 
                        ~ exp(mySpatial + Intercept + log_Depth), n.samples = 20, seed=seed)

multiplot(ggplot() + gg(pred_int_WW1[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$mean,pred_int_WW3@data$mean),probs = c(0.005,0.995))) + ggtitle('Joint Model 1 Mean'),
          ggplot() + gg(pred_int_WW1[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$sd,pred_int_WW3@data$sd),probs = c(0.005,0.995))) + ggtitle('Joint Model 1 SD'),
          ggplot() + gg(pred_int_WW3[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$mean,pred_int_WW3@data$mean),probs = c(0.005,0.995))) + ggtitle('Joint Model 3 Mean'),
          ggplot() + gg(pred_int_WW3[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(quantile(c(pred_int_WW1@data$sd,pred_int_WW3@data$sd),probs = c(0.005,0.995))) + ggtitle('Joint Model 3 SD'),
          layout = matrix(c(1:4),nrow=2,ncol=2,byrow = F))
```

Again, this third model seems to be predicting unrealistically high whale densities away from the tracklines. Let's restrict our plot to those pixels within 30 km of nearest trackline

```{r, message=F, cache=TRUE}
pred_int_WW3_restricted <- pred_int_WW3[restricted_ind,]

multiplot(ggplot() + gg(pred_int_WW1_restricted[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$mean,pred_int_WW3_restricted@data$mean)) + ggtitle('Joint Model 1 Mean'),
          ggplot() + gg(pred_int_WW1_restricted[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$sd,pred_int_WW3_restricted@data$sd)) + ggtitle('Joint Model 1 SD'),
          ggplot() + gg(pred_int_WW3_restricted[1]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$mean,pred_int_WW3_restricted@data$mean)) + ggtitle('Joint Model 3 Mean'),
          ggplot() + gg(pred_int_WW3_restricted[2]) + gg(Domain) + gg.spatiallines_mod(Effort_survey, colour='red') +
            colsc(c(pred_int_WW1_restricted@data$sd,pred_int_WW3_restricted@data$sd)) + ggtitle('Joint Model 3 SD'),
          layout = matrix(c(1:4),nrow=2,ncol=2,byrow = F))

# What is the estimated popualation size?
Lambda_WW3 <- predict(fit_combined3, predpts, ~ sum(weight * exp(mySpatial + Intercept +
                                                                   log_Depth)), n.samples = 20, seed=seed)
Lambda_WW3
Lambda_df <- rbind(Lambda_WW1,Lambda_WW2,Lambda_WW3,Lambda,Lambda2)
Lambda_df$Model <- c('Joint Model 1','Joint Model 2','Joint Model 3','Survey-only no depth','Survey-only with depth')
ggplot(Lambda_df,aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar()
# and in the restricted region?
Lambda_WW3_restricted <- predict(fit_combined3, predpts_restricted, ~ sum(weight * exp(mySpatial + Intercept +
                                                                                         log_Depth)), n.samples = 20, seed=seed)
Lambda_WW3_restricted
Lambda_df_restricted <- rbind(Lambda_WW1_restricted,Lambda_WW2_restricted,Lambda_WW3_restricted,Lambda_restricted,Lambda2_restricted)
Lambda_df_restricted$Model <- c('Joint Model 1','Joint Model 2','Joint Model 3','Survey-only no depth','Survey-only with depth')
ggplot(Lambda_df_restricted,aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar() + ggtitle('Estimated Population Size in Restricted Region')
```

We find a qualitatively similar map of intensity compared with the first model, without the numerical instability seen in the second model. Estimates of population size across both the restricted and unrestricted domains are very similar to those from the first model, albeit with slightly reduced credible interval widths. Whilst this may change with the addition of more posterior samples, the shorter credible intervals are to be expected since we are 'adding in information' into the model in the form of a prior distribution on the relative effort.

What is the estimated relative effort across the two ports? Given that we have normalised the effort fields by their total integrals, we can assess the estimated relative effort by simply assessing the posterior marginal distribution of the exponential of `Diff_QQ_B_Q`.

```{r, cache=TRUE}
# First plot the posterior distribution of the parameter on the log scale
plot(fit_combined3,'Diff_QQ_B_Q')
# To get the posterior of the exponential of the parameter, we can sample from the model. 
samples_WW3 <- generate(fit_combined3,n.samples = 20, seed=seed) #already sampled
Diff_QQ_B_Q_samples <- sapply(samples_WW3, FUN = function(x){return(exp(x$Diff_QQ_B_Q))})
Diff_QQ_B_Q_samples <- 
  data.frame(mean=c(mean(Diff_QQ_B_Q_samples),3.22),
             sd=c(sd(Diff_QQ_B_Q_samples),0.1),
             LCL=c(quantile(Diff_QQ_B_Q_samples,probs=0.025),exp(log(3.22)-2*0.1)),
             UCL=c(quantile(Diff_QQ_B_Q_samples,probs=0.975),exp(log(3.22)+2*0.1)),
                                  name=factor(c('Posterior Relative Effort','Prior Relative Effort')))
ggplot(Diff_QQ_B_Q_samples, aes(x=name, y=mean, ymax=UCL, ymin=LCL)) +
  geom_point() + geom_errorbar() + xlab('') + ylab('Relative Effort')
```

Finally, we plot the estimated effects of depth across the three models. We also include a vertical line showing the 90th percentile of the log_Depth values observed at the survey tracklines.

```{r, cache=TRUE}
samples_WW1 <- generate(fit_combined1,n.samples = 20, seed=seed)
samples_WW2 <- generate(fit_combined2,n.samples = 20, seed=seed)
#samples_WW3 <- generate(fit_combined3,n.samples = 20, seed=seed)

# What is the upper 90th percentile of log depth seen by transect line?
max_depth_obs <- quantile(over(Effort_survey,log_Depth)$log_Depth, probs=c(0.90))

depthpred_WW1 <- sapply(samples_WW1,FUN = function(x){return(exp(depthdf$log_Depth*x$log_Depth))})

depthpred_WW2 <- sapply(samples_WW2,FUN = function(x){return(exp(depthdf$log_Depth*x$log_Depth))})

depthpred_WW3 <- sapply(samples_WW1,FUN = function(x){return(exp(depthdf$log_Depth*x$log_Depth))})

multiplot(
ggplot(data.frame(mean=apply(depthpred_WW1,1, mean),
                  LCL=apply(depthpred_WW1,1, quantile, probs=c(0.025)),
                  UCL=apply(depthpred_WW1,1, quantile, probs=c(0.975)),
                  logdepth=seq(from=min(log_Depth@data$log_Depth),
                            to=max(log_Depth@data$log_Depth),
                            length.out = 100)),
       aes(y=mean,x=logdepth,ymax=UCL,ymin=LCL)) +
  geom_line() + geom_ribbon(alpha=0.4) +
  geom_vline(xintercept = max_depth_obs) +
  ylab('Relative intensity change'),

ggplot(data.frame(mean=apply(depthpred_WW2,1, mean),
                  LCL=apply(depthpred_WW2,1, quantile, probs=c(0.025)),
                  UCL=apply(depthpred_WW2,1, quantile, probs=c(0.975)),
                  logdepth=seq(from=min(log_Depth@data$log_Depth),
                               to=max(log_Depth@data$log_Depth),
                               length.out = 100)),
       aes(y=mean,x=logdepth,ymax=UCL,ymin=LCL)) +
  geom_line() + geom_ribbon(alpha=0.4) +
  geom_vline(xintercept = max_depth_obs) +
  ylab('Relative intensity change'),

ggplot(data.frame(mean=apply(depthpred_WW3,1, mean),
                  LCL=apply(depthpred_WW3,1, quantile, probs=c(0.025)),
                  UCL=apply(depthpred_WW3,1, quantile, probs=c(0.975)),
                  logdepth=seq(from=min(log_Depth@data$log_Depth),
                               to=max(log_Depth@data$log_Depth),
                               length.out = 100)),
       aes(y=mean,x=logdepth,ymax=UCL,ymin=LCL)) +
  geom_line() + geom_ribbon(alpha=0.4) +
  geom_vline(xintercept = max_depth_obs) +
  ylab('Relative intensity change'),
layout = matrix(1:3, nrow=1, ncol=3, byrow=T))

```

As a result of the relatively small number of sightings, we see a huge level of uncertainty associated with the parameter estimate.

## Model comparison on the test data
We will now use the survey data from 2011 that we held out to compare our models. We will assume that the space use of the whales remained constant (i.e. no changes to their density occurred) from 2007-2011. We will predict the number of sightings expected to be found from the 2011 survey, based on the locations of the survey's tracklines, from both the best joint models and the survey-only models.

```{r, warning=F, message=F, cache=TRUE}
int_test <- ipoints(samplers = Effort_survey_test, domain = mesh_land,name='space')
# the probability of making a sighting >4km away estimated to be negligible
int_test_dist <- ipoints(domain = INLA::inla.mesh.1d(seq(0.25, 4, length.out = 30)),
                         name='distance')
# This defines integration points in both 2D space and 1D distance dimensions
int_test_prod <- cprod(int_test,int_test_dist)

ggplot() + gg(Domain) + gg(int_test_prod) + gg.spatiallines_mod(Effort_survey_test, colour='pink')
# Where do these points come from? They are the mesh vertices!
ggplot() + gg(mesh_land) + gg(int_test_prod) + gg.spatiallines_mod(Effort_survey_test, colour='pink')

sum(int_test_prod$weight)
sum(int_test$weight) 
# Notice that the sum of the product weights are 4 times larger, due to the distance mesh extending 4km out from each line. We still need to scale by 2 again by adding log(2), to account for sightings taking place both sides of the tracklines!

# We need to remove the 3rd dimension that has been added
int_test_prod@coords <- int_test_prod@coords[,c(1:2)]
int_test_prod@bbox <- int_test_prod@bbox[c(1:2),]

Lambda_test_fit_combined <- 
  predict(fit_combined3, int_test_prod, 
          ~ rpois(1,
                  lambda = sum( weight * exp(mySpatial + Intercept + log_Depth 
                             + log_hn(distance,lsig) + log(2)))),
                   n.samples=200, seed=seed)

Lambda_test_fit_combined

Lambda_test_fit_single <- 
  predict(fit2, int_test_prod, 
          ~ rpois(1,
                  lambda = sum( weight * exp(mySpatial + Intercept + log_Depth 
                             + log_hn(distance,lsig) + log(2)))),
                   n.samples=200, seed=seed)

Lambda_test_fit_single

Lambda_test_fit_single_nocov <- 
  predict(fit, int_test_prod, 
          ~ rpois(1,
                  lambda = sum( weight * exp(mySpatial + Intercept 
                             + log_hn(distance,lsig) + log(2)))),
                   n.samples=200, seed=seed)

Lambda_test_fit_single_nocov

# How many sightings were made in the survey in 2011?
dim(Sightings_survey_test@coords) #15

Lambda_tests <- rbind(Lambda_test_fit_combined,
                      Lambda_test_fit_single,
                      Lambda_test_fit_single_nocov)
Lambda_tests$Model <- factor(c('Joint Model 3', 'Survey-only Model with log_Depth','Survey-only Model without covariates'))
ggplot(Lambda_tests, aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar() + 
  geom_hline(yintercept = 15, colour='red',linetype='dashed')

```

We see that all three models under-estimate the total observed number of sightings, but that all three models contain the observed value within their 95% credible intervals. There may be a slight improvement offered by the joint model with respect to point estimates and uncertainty quantification, but the difference is minor. 

An alternative approach for model comparison is to compare the spatial distribution of the points with respect to the fitted intensity surfaces. In other words, how well do our models capture the spatial distribution of 2011's whale intensity.

Few methods exist for investigating this for log-Gaussian Cox process models. One idea could be to map each sighting location to the closest mesh vertex and each sighting distance value to the closest value in the 1D mesh used. Then, we could evaluate the Poisson density function of the counts evaluated at every combination of mesh vertices and distances. This would provide a score function for us to compare the models. By sampling from the posterior, we can approximate the posterior distribution for these scores.

```{r, cache=TRUE}
# Loop through sightings. Find closest mesh locations and distance value.
int_ind <- rep(NA, dim(Sightings_survey_test@coords)[1])
int_test_prod$count <- 0
# loop through the sightings
for(i in 1:dim(Sightings_survey_test@coords)[1])
{
  int_ind[i] <- intersect(
    # find the closest spatial index in the integration points
    as.numeric(apply(gDistance(int_test_prod ,Sightings_survey_test[i,],
                    byid=T),
          1,FUN = function(x){which(x==min(x))})),
    # find the closest 1D index for the distances
    which(abs(Sightings_survey_test$DISTANCE[i]-int_test_prod$distance) ==
            min(abs(Sightings_survey_test$DISTANCE[i]-int_test_prod$distance)))
    )
  # Update the count by 1
  int_test_prod$count[int_ind[i]] <- int_test_prod$count[int_ind[i]] + 1
}

# Now evaluate the posterior mean of the Poisson score function for the models
# Higher values of score indicate a better model fit
Score_joint <- 
  predict(fit_combined3, int_test_prod, 
          ~ sum(dpois(count,
                  lambda = weight * exp(mySpatial + Intercept + log_Depth
                             + log_hn(distance,lsig) + log(2)),
                  log = T)),
                  n.samples=200, seed=seed)
Score_joint

Score_cov <- 
  predict(fit2, int_test_prod, 
          ~ sum(dpois(count,
                  lambda = weight * exp(mySpatial + Intercept + log_Depth
                             + log_hn(distance,lsig) + log(2)),
                  log = T)),
                  n.samples=200, seed=seed)
Score_cov

Score_nocov <- 
  predict(fit, int_test_prod, 
          ~ sum(dpois(count,
                  lambda = weight * exp(mySpatial + Intercept 
                             + log_hn(distance,lsig) + log(2)),
                  log = T)),
                  n.samples=200, seed=seed)
Score_nocov

Scores <- rbind(Score_joint,
                Score_cov,
                Score_nocov)
Scores$Model <- factor(c('Joint Model 3', 'Survey-only Model with log_Depth','Survey-only Model without covariates'))
ggplot(Scores, aes(x=Model, y=mean, ymax=q0.975, ymin=q0.025)) +
  geom_point() + geom_errorbar() + 
  ylab('Score') + ggtitle('Posterior Scores of the 3 Models')
```

So what do we find out? We see that including the log_Depth in a model for the whale intensity failed to improve either the predictions of the total number of encounters in 2011, or the predicted spatial distribution of these encounters. Furthermore, incorporating the whale watch sightings also failed to improve either measure of predictive performance.

So why haven't things improved? For starters, the test dataset used for model comparison contained only 15 sightings. Thus only huge differences in model fit would likely be detected by the scoring approach. Secondly, we made strong assumptions that: the whale density did not change across the three months, each survey followed identical protocols with identical detection functions and the whale density in 2011 matched that in 2007-2009. Finally, even if we did improve the accuracy of our maps of whale intensity in the regions in close proximity to the whale watch ports, it is likely that neither of our model comparison measures would detect this. This is because the survey effort in 2011 took place largely outside of these regions.

What have we gained? For starters, by including the whale watch data within a joint model, we gained knowledge about a possible relationship between whale density and bathymetry. Of course, the causal DAG introduced in the third lecture would tell us to be cautious: the detected trend could be due to confounding with terms that truly drive whale watch effort! Additionally, we now have a model for the number of sightings to be expected from the whale watch companies given an estimate of their total efforts. This could be used to detect large changes in the whale intensity within the waters in close proximity to their ports. 

In the interests of computation time, we only considered a small subset of the total data available on the fin whales for this workshop. It would be interesting to repeat this modelling process on the entire data! The resolution, precision, and accuracy of the intensity maps would likely increase greatly, as would the gaps in performance between the joint and survey-only models. In addition to the survey and whale watch data, opportunistic sightings from commercial vessels and other sources are also available. These could also be included in a joint model, with estimates of effort coming from AIS layers! Many of the numerical instabilities we faced with fitting these models would also disappear with more data!


<!-- 1) Refit the 'best' joint model (`fit_combined3`), but replace log_Depth with sea surface temperature. Hint: Remember to redefine the components and formulae (including for the survey model!)! If you get stuck, look at the answers below. Note that including both log_Depth and SST will lead to severe instabilities. -->

<!-- # cmp_WW_Combined4 <- ~ mySpatial_Brier(main = coordinates, copy='mySpatial', fixed=T) +  -->
<!-- #   mySpatial_Quoddy(main = coordinates, copy='mySpatial', fixed=T) +  -->
<!-- #   Dist_Quoddy_sq(main=Dist_Quoddy_sq, model='offset') + -->
<!-- #   Dist_Brier_sq(main=Dist_Brier_sq, model='offset') + -->
<!-- #   Intercept_WW_Q(1) + -->
<!-- #   Diff_QQ_B_Q(main=1,model='linear',mean.linear=1.17, prec.linear=100) + -->
<!-- #   mySpatial(main = coordinates, model = matern_land) +  -->
<!-- #   Intercept(1) + -->
<!-- #   lsig(1) + -->
<!-- #   Quoddy_par(1) + -->
<!-- #   Brier_par(1) + -->
<!-- #   SST(main = SST_sp, model='linear') -->
<!-- #  -->
<!-- # formula_WW_B4 = coordinates ~ mySpatial_Brier + -->
<!-- #   Dist_Brier_sq*Brier_par +  -->
<!-- #   Intercept_WW_Q +  -->
<!-- #   Diff_QQ_B_Q + -->
<!-- #   SST + -->
<!-- #   int_dist_Brier(Brier_par) -->
<!-- #  -->
<!-- # formula_WW_Q4 = coordinates ~ mySpatial_Quoddy + -->
<!-- #   Dist_Quoddy_sq*Quoddy_par +  -->
<!-- #   Intercept_WW_Q + -->
<!-- #   SST + -->
<!-- #   int_dist_Quoddy(Quoddy_par) -->
<!-- #  -->
<!-- # formula_survey_4 = coordinates + distance ~ mySpatial + Intercept +  -->
<!-- #   SST + log_hn(distance, lsig) + log(2) -->
<!-- #  -->
<!-- # fit_WW_B4 = like(data = Sightings_Brier_nodup, -->
<!-- #                  domain = list( -->
<!-- #                    coordinates = mesh_land), -->
<!-- #                  formula = formula_WW_B4, -->
<!-- #                  family = 'cp') -->
<!-- #  -->
<!-- # fit_WW_Q4 = like(data = Sightings_Quoddy_nodup, -->
<!-- #                  domain = list( -->
<!-- #                    coordinates = mesh_land), -->
<!-- #                  formula = formula_WW_Q4, -->
<!-- #                  family = 'cp') -->
<!-- #  -->
<!-- # fit_extra2_like = like(data = Sightings_survey, -->
<!-- #             samplers = Effort_survey, -->
<!-- #             domain = list( -->
<!-- #               coordinates = mesh_land, -->
<!-- #               distance = INLA::inla.mesh.1d(seq(0, 2, length.out = 30))), -->
<!-- #             formula = formula_survey_4, -->
<!-- #             family = 'cp') -->
<!-- #  -->
<!-- #  fit_combined4 <- bru(fit_extra2_like, fit_WW_B4, fit_WW_Q4, components = cmp_WW_Combined4) -->
<!-- # #fit_combined4 <- readRDS('./Model_Files/fit_combined4.rds') -->
<!-- # fit_combined4$dic$dic #DIC is 2308 - performance in-between the other 2 models -->
<!-- # fit_combined3$dic$dic # -->
<!-- # summary(fit_combined4) -->



### Exercise {#Ex6}
Throughout the modelling stages, we assumed a half-normal detection function. Re-fit the 'best' joint model, but replacing the half-normal detection function with the following hazard rate model with shape parameter 5. How does the model compare with the half-normal model? Are there any significant changes to the parameter estimates? Can you spot the evidence that the model has not properly fit (note the prior distribution used!). HINT: The model fitting for this model is very unstable and slow. Once you have built the like object, run `fit_combined4 <- readRDS('./Model_Files/fit_combined4.rds')` to load a pre-fitted model object.


```{r, cache=T}
hr <- function(distance, lsig) {
  1 - exp(-( (distance-0.25) / (exp(lsig)))^-5)
}
log_hr <- function(...){log(hr(...))}
```

<div class="fold s o">
```{r, message=F, warning=F, cache=TRUE}
cmp_WW_Combined4 <- ~ 
  mySpatial_Brier(main = coordinates, copy='mySpatial', fixed=T) + 
  mySpatial_Quoddy(main = coordinates, copy='mySpatial', fixed=T) + 
  Dist_Quoddy_sq(main=Dist_Quoddy_sq, model='offset') +
  Dist_Brier_sq(main=Dist_Brier_sq, model='offset') +
  Intercept_WW_Q(1) +
  Diff_QQ_B_Q(main=1,model='linear',mean.linear=1.17, prec.linear=100) +
  mySpatial(main = coordinates, model = matern_land) + 
  log_Depth(main = log_Depth, model='linear') +
  Intercept(1) +
  lsig(1) +
  Quoddy_par(1) +
  Brier_par(1)

formula_WW_B4 = coordinates ~ mySpatial_Brier +
  Dist_Brier_sq*Brier_par + 
  Intercept_WW_Q + 
  Diff_QQ_B_Q +
  int_dist_Brier(Brier_par) +
  log_Depth

formula_WW_Q4 = coordinates ~ mySpatial_Quoddy +
  Dist_Quoddy_sq*Quoddy_par + 
  Intercept_WW_Q +
  int_dist_Quoddy(Quoddy_par) +
  log_Depth

formula_survey_4 = coordinates + distance ~ mySpatial + Intercept + 
  log_Depth + log_hr(distance, lsig) + log(2)

fit_WW_B4 = like(data = Sightings_Brier_nodup,
                 domain = list(
                   coordinates = mesh_land),
                 formula = formula_WW_B4,
                 family = 'cp')

fit_WW_Q4 = like(data = Sightings_Quoddy_nodup,
                 domain = list(
                   coordinates = mesh_land),
                 formula = formula_WW_Q4,
                 family = 'cp')

fit_extra2_like = like(data = Sightings_survey,
             samplers = Effort_survey,
             domain = list(
               coordinates = mesh_land,
               distance = INLA::inla.mesh.1d(seq(0.25, 2, length.out = 30))),
             formula = formula_survey_4,
             family = 'cp')

 #fit_combined4 <- bru(fit_extra2_like, fit_WW_B4, fit_WW_Q4, components = cmp_WW_Combined4,options = list(bru_initial = list(lsig = 0.2)))
fit_combined4 <- readRDS('./Model_Files/fit_combined4.rds')
fit_combined3$dic$dic #DIC is 2308 
fit_combined4$dic$dic #DIC is 2642 - much worse with this detection function

summary(fit_combined4)
```
</div>

<div class="fold s o">
Again, to run this yourself with the known initial values, run:
```{r, eval=F, cache=T}
fit_combined4 <- bru(fit_extra2_like, fit_WW_B4, fit_WW_Q4, components = cmp_WW_Combined4, 
                     options = bru_options(bru_initial=readRDS('./Model_Files/states_combined4.rds'),
            bru_max_iter = 1))
```
</div>

### Exercise {#Ex7}
Now, predict the fitted detection function from `fit_combined4` and compare it with the detection function estimated from `fit_combined3`. Combine the two into a single plot using `multiplot`. HINT: You may need to use the `generate` and `sapply` method if an error message is returned when using `predict`.

<div class="fold s o">
```{r, cache=TRUE}
distdf <- data.frame(distance = seq(0, 2, length = 100))
dfun_fc3 <- generate(fit_combined3, n.samples = 20)
dfun_fc3 <- sapply(dfun_fc3, FUN = function(x){exp(log_hn(distdf$distance, as.numeric(x$lsig)))})
  
dfun_fc4 <- generate(fit_combined4, n.samples = 20)
dfun_fc4 <- sapply(dfun_fc4, FUN = function(x){exp(log_hr(distdf$distance, as.numeric(x$lsig)))})

dfun_df <- data.frame(distance=distdf$distance,
                      mean_hnorm=apply(dfun_fc3,1,mean),
                      mean_hazard=apply(dfun_fc4,1,mean),
                      LCL_hnorm=apply(dfun_fc3,1,quantile,probs=0.025),
                      UCL_hnorm=apply(dfun_fc3,1,quantile,probs=0.975),
                      LCL_hazard=apply(dfun_fc4,1,quantile,probs=0.025),
                      UCL_hazard=apply(dfun_fc4,1,quantile,probs=0.975)
                      )
multiplot(
  ggplot(dfun_df,aes(x=distance, y=mean_hnorm, ymax=UCL_hnorm, ymin=LCL_hnorm)) +
    geom_line() + geom_ribbon(alpha=0.4, colour='red', fill='red') +
    ylab('Probability of detection half normal'),
  ggplot(dfun_df,aes(x=distance, y=mean_hazard, ymax=UCL_hazard, ymin=LCL_hazard)) +
    geom_line() + geom_ribbon(alpha=0.4, colour='blue', fill='blue')  +
    ylab('Probability of detection hazard (shape 5)'),
  layout=matrix(1:2, nrow=2, ncol=1, byrow = T)
)
```

</div>

### Exercise {#Ex8}
Plot a map of the estimated **search effort half-normal functions** from both ports. What do you notice? Is this realistic? HINT: To get the half-normal functions we want to investigate the quantity `exp(Dist_Brier_sq*Brier_par)` and `exp(Dist_Quoddy_sq*Quoddy_par`.

<div class="fold s o">
```{r, message=F, cache=TRUE}
Dist_Brier_sq_plot4 <- pixels(mesh=mesh_land,mask=Domain)
Dist_Brier_sq_plot4 <- predict(fit_combined4,Dist_Brier_sq_plot4,~exp(Dist_Brier_sq*Brier_par),n.samples = 20, seed=seed)
ggplot() + gg(Dist_Brier_sq_plot4[1]) + colsc(Dist_Brier_sq_plot4[1]$mean) + 
  gg(Sightings_Brier_nodup,colour='green') + gg(Domain)  +
  ggtitle('Brier Relative Effort Intensity')

Dist_Quoddy_sq_plot4 <- pixels(mesh=mesh_land,mask=Domain)
Dist_Quoddy_sq_plot4 <- predict(fit_combined4,Dist_Quoddy_sq_plot4,~exp(Dist_Quoddy_sq*Quoddy_par),n.samples = 20, seed=seed)
ggplot() + gg(Dist_Quoddy_sq_plot4[1]) + colsc(Dist_Quoddy_sq_plot4[1]$mean) + 
  gg(Sightings_Quoddy_nodup,colour='green') + gg(Domain) +
  ggtitle('Quoddy Relative Effort Intensity')

# The model is predicting that the whale watch vessels departing from Quoddy are spreading uniformly across the entire domain and visiting each point with almost constant intensity! This is not realistic and shows that the model is unsuitable
```
</div>


### (BONUS CHALLENGING) Exercise {#Ex9}
Additional opportunistic sightings are available in the SpatialPointsDataFrame object `Sightings_Opp_sp`. Obtain AIS vessel density data, or manually create a rough one by hand.  Try to incorporate these additional sightings into a model. What changes? 

### Closing Notes

It is important to note that the instability seen in some of the models used in these workshops can be atttributed to the small sizes of the datasets used in these workshops. We are fitting complex Bayesian models to point pattern datasets with only a limited number of events.

In practice, when this general framework is applied to much larger datasets, these numerical instabilities will disappear. More complex terms such as nonlinear covariate terms, covariate interactions, temporal and seasonal effects, and spatio-temporal terms can all be considered and may substantially improve model fit. For completeness, we briefly demonstrate the code required to fit spatio-temporal models next.

### Bonus content - How to fit a spatio-temporal model in inlabru?

inlabru allows for kronecker product separable spaitio-temporal models to be easily defined. First, we would need to define integration points manually using the `ipoints` function. 

```{r, eval=F}
ips <- ipoints(Effort_survey, mesh_land, group = "YEAR")
```

Next we would need to modify the `mySpatial` term within the components as follows:

```{r, eval=F}
cmp <- LHSstuff ~ RHSstuff + mySpatial(main = coordinates, model = matern_land,
                                       group = YEAR, ngroup = 3,
                                       control.group(model='?'))
```

where `'?'` can be iid for independent spatial fields each year ar1 for an autoregressive separable spatio-temporal field see `?control.group` for possible models

### Links to Every Exercise and Bonus Exercise

We cannot fit a spatio-temporal model to our data due to insufficient data and due to the survey tracklines visiting non-overlapping regions (non-randomly) each year!

6. [Exercise 1](#Ex6)
7. [Exercise 2](#Ex7)
8. [Exercise 3](#Ex8)
9. [Bonus Exercise](#Ex9)

### Messages of Thanks

These workshops would not have been possible without the extensive organisational and data-preparation efforts of Shelley Lang and Catalina Gomez. I thank you both! Additionally, I would like to thank Marie Auger-Méthé for all her efforts with reviewing and reformatting these sessions. Finally, I would like to thank Finn Lindgren for making a stable release version of `inlabru` in time for these workshops and for providing coding assistance.